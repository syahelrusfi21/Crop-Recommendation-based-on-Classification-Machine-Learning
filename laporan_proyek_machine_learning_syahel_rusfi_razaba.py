# -*- coding: utf-8 -*-
"""Laporan Proyek Machine Learning - Syahel Rusfi Razaba

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mxjee4Fdr-iBBYZxKR1tFzn1EyeTXxk4

# **Laporan Proyek Machine Learning - Syahel Rusfi Razaba**
*Prediksi Jenis Tanaman Optimal Berdasarkan Karakteristik Tanah dan Iklim Menggunakan Model Klasifikasi Machine Learning*

## **Import Library**
Mengimpor berbagai pustaka (*library*) Python yang digunakan untuk proses analisis data, visualisasi, dan pemodelan machine learning. Pustaka utama yang digunakan antara lain pandas, seaborn, matplotlib, dan pustaka dari scikit-learn.
"""

# Import Library
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import joblib
import warnings
warnings.filterwarnings("ignore")

"""## **Load Dataset**
Membaca dataset `Crop_recommendation.csv` yang berisi data terkait karakteristik tanah dan iklim, serta label jenis tanaman yang direkomendasikan. Dataset ini memiliki 7 fitur numerik dan 1 kolom target (label) berupa jenis tanaman.
"""

# Load Dataset
df = pd.read_csv("https://github.com/syahelrusfi21/Prediksi-Jenis-Tanaman-Berdasarkan-Tanah-dan-Iklim/raw/main/dataset/Crop_recommendation.csv")
df.head()

# Informasi dataset
print("Informasi Dataset:")
df.info()

"""## **Data Understanding**
Dataset yang digunakan adalah Crop Recommendation Dataset yang diperoleh dari [Kaggle](https://www.kaggle.com/datasets/madhuraatmarambhagat/crop-recommendation-dataset).
### Informasi Dataset:
- Jumlah sampel: 2200 baris
- Jumlah fitur: 7 fitur input + 1 target output
- Target: Nama tanaman (*multi-class*)

### Fitur:
| Fitur | Deskripsi |
| ------ | ------ |
| N | Kandungan Nitrogen dalam tanah |
| P | Kandungan Fosfor dalam tanah |
| K | Kandungan Kalium dalam tanah |
| temperature | Rata-rata suhu udara (¬∞C) |
| humidity | Rata-rata kelembapan relatif (%) |
| ph | Tingkat keasaman tanah (ph tanah) |
| rainfall | Curah hujan dalam mm |
| label | Tanaman (kelas target/output) |

## **Data Pre-Processing**

### Data Cleaning
Pemeriksaan kualitas data dilakukan pada tahap ini, yang meliputi deteksi dan penanganan:
- Data duplikat
- Nilai kosong (missing values)
- Outlier
"""

# Cek data duplikat
print("Jumlah data duplikat:", df.duplicated().sum())

# Cek missing value
print("Jumlah missing value per kolom:")
print(df.isnull().sum())

# Visualisasi Outlier dengan Boxplot
numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns

plt.figure(figsize=(15, 10))
for i, col in enumerate(numerical_cols):
    plt.subplot(2, 4, i + 1) # Sesuaikan grid berdasarkan jumlah kolom numerik
    sns.boxplot(y=df[col])
    plt.title(f'Boxplot of {col}')
plt.tight_layout()
plt.show()

"""Terlihat terdapat outlier pada beberapa variabel. Untuk menangani outlier ini, kita akan menggunakan metode transformasi yang disebut Winsorization (Capping).

Pada metode ini, nilai outlier tidak dihapus, melainkan diganti dengan nilai batas atas atau batas bawah yang dihitung berdasarkan Interquartile Range (IQR). Nilai yang melebihi Q3 + 1.5√óIQR akan diganti dengan batas atas, dan nilai yang kurang dari Q1 - 1.5√óIQR akan diganti dengan batas bawah.

Pendekatan ini dipilih untuk menjaga ukuran dataset tetap utuh sekaligus mengurangi dampak nilai ekstrem pada analisis.
"""

# Salin data asli
df_transformed = df.copy()

# Daftar fitur numerik
numerical_features = df_transformed.drop(columns='label').columns

# Winsorization: Batasi nilai outlier ke batas IQR
for col in numerical_features:
    Q1 = df_transformed[col].quantile(0.25)
    Q3 = df_transformed[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    df_transformed[col] = np.where(df_transformed[col] < lower_bound, lower_bound,
                            np.where(df_transformed[col] > upper_bound, upper_bound, df_transformed[col]))

# Visualisasi Outlier dengan Boxplot setelah Transformasi
numerical_cols_transformed = df_transformed.select_dtypes(include=['float64', 'int64']).columns

plt.figure(figsize=(15, 10))
for i, col in enumerate(numerical_cols_transformed):
    plt.subplot(2, 4, i + 1) # Sesuaikan grid berdasarkan jumlah kolom numerik
    sns.boxplot(y=df_transformed[col])
    plt.title(f'Boxplot of {col}')
plt.tight_layout()
plt.show()

"""Setelah melakukan transformasi, terlihat pada visualisasi boxplot di atas bahwa outlier sudah ditangani.

### Exploratory Data Analysis (EDA)
EDA bertujuan memahami pola dan distribusi dalam data, serta membantu mengenali hubungan antar fitur. Analisis dilakukan melalui:
- Statistik deskriptif
- Korelasi antar fitur
- Visualisasi distribusi kelas target
"""

# Statistik deskriptif
print("\nStatistik Deskriptif:")
print(df_transformed.describe())

# Korelasi antar fitur
plt.figure(figsize=(10, 6))
sns.heatmap(df_transformed.corr(numeric_only=True), annot=True, cmap="YlGnBu", fmt=".2f")
plt.title("Correlation Heatmap of Features")
plt.show()

"""Berdasarkan visualisasi heatmap di atas, terlihat bahwa tidak ada korelasi yang sangat kuat antar variabel bebas. Hal ini mengindikasikan bahwa data tidak menunjukkan adanya multikolinearitas yang signifikan, sehingga cukup baik untuk digunakan dalam pemodelan."""

# Distribusi kelas target
plt.figure(figsize=(12, 6))
sns.countplot(y='label', data=df_transformed, order=df_transformed['label'].value_counts().index)
plt.title("Distribusi Jenis Tanaman")
plt.xlabel("Jumlah")
plt.ylabel("Jenis Tanaman")
plt.show()

"""Berdasarkan visualisasi kelas target, terlihat bahwa distribusi data di setiap kelas seimbang (tidak *imbalanced*).

### Data Splitting and Transformation
Dataset dibagi menjadi dua bagian:
- 80% Data Latih (*Training Set*): Digunakan untuk melatih model
- 20% Data Uji (*Test Set*): Digunakan untuk mengevaluasi performa model

Transformasi dilakukan agar data dalam bentuk numerik dan memiliki skala yang seragam:

- **Label Encoding**: Mengubah label tanaman dari bentuk teks menjadi nilai numerik menggunakan LabelEncoder.
- **Normalisasi**: Menggunakan MinMaxScaler untuk mengubah skala semua fitur numerik ke rentang 0‚Äì1 agar seimbang dalam perhitungan algoritma.
"""

# Pisahkan fitur dan label
X = df_transformed.drop("label", axis=1)
y = df_transformed["label"]

# Encode target
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

# Normalisasi fitur hanya pada data latih dan terapkan pada data uji
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"Jumlah data latih: {X_train_scaled.shape[0]}")
print(f"Jumlah data uji: {X_test_scaled.shape[0]}")

"""## **Modeling**
Melatih tiga algoritma klasifikasi yang umum digunakan dalam *supervised learning*:
- K-Nearest Neighbors (KNN)
- Decision Tree
- Random Forest
"""

# Inisialisasi model
models = {
    "KNN": KNeighborsClassifier(),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42)
}

# Melatih & evaluasi model
results = {}

for name, model in models.items():
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
    acc = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred, target_names=le.classes_, output_dict=True)
    results[name] = {
        "accuracy": acc,
        "f1_score": report["weighted avg"]["f1-score"],
        "precision": report["weighted avg"]["precision"],
        "recall": report["weighted avg"]["recall"]
    }

# Tampilkan hasil
pd.DataFrame(results).T.sort_values(by="accuracy", ascending=False)

"""## **Evaluation**
Menampilkan confusion matrix dari model terbaik (Random Forest) untuk memperlihatkan detail klasifikasi per kelas. Matriks ini berguna untuk mengidentifikasi jumlah prediksi benar dan salah, serta menilai distribusi kesalahan model terhadap tiap kelas tanaman.
"""

# üìè 6. Confusion Matrix untuk Model Terbaik (Random Forest)
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train_scaled, y_train)
y_pred_rf = rf.predict(X_test_scaled)

cm = confusion_matrix(y_test, y_pred_rf)
plt.figure(figsize=(12, 10))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=le.classes_, yticklabels=le.classes_)
plt.title("Confusion Matrix - Random Forest")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

"""## **Save Best Model**
Menyimpan model Random Forest yang telah dilatih menggunakan library joblib. Model yang disimpan dapat digunakan kembali tanpa perlu melatih ulang.
"""

# Simpan model Random Forest terbaik
joblib.dump(rf, 'random_forest_model.pkl')

print("Model Random Forest terbaik telah disimpan sebagai 'random_forest_model.pkl'")